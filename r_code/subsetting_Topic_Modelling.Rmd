---
title: "Topic modeling subsetting"
output: 
---


```{r}
library(stm)
require(caTools)
require(dplyr)
library(topicmodels)
library(MASS)
require(quanteda)
require(lubridate)
require(corpus)
```



```{r}
load("Corp_HouseOfCommons.RData")
load("uk_toy.RData")
head(uk_toy, 20)
uk_labour<- subset(uk_toy, party=="Lab")
uk_cons<- subset(uk_toy, party=="Con")

#uk_toy <- sample_n(hoc.corpus, 500)
#saveRDS(uk_toy, file = "uk_toy.rds")
```

```{r}
speech.corpus <- corpus(uk_cons)

uk_concerv <- corpus_subset(speech.corpus, year(docvars(speech.corpus, 'date')) >= 2001-01-01)

ndoc(uk_concerv)
```


```{r}
speeches_new_dfm <- dfm(uk_concerv, remove_punct = TRUE, remove = stopwords('en')) %>% 
            dfm_remove(c('*-time', '*-timeUpdated', 'GMT', 'BST')) %>% 
            dfm_trim(min_termfreq = 0.90, termfreq_type = "quantile", 
                     max_docfreq = 0.5, docfreq_type = "prop")
speeches_new_dfm <- speeches_new_dfm[ntoken(speeches_new_dfm) > 0,]

head(speeches_new_dfm, 2)
```


```{r}
dtm <- convert(speeches_new_dfm, to = "topicmodels")
lda <- LDA(dtm, k = 20)

terms(lda, 9)

```

```{r}

topic.count <- 20
dfm2stm <- convert(speeches_new_dfm, to = "stm")
model.stm <- stm(dfm2stm$documents, dfm2stm$vocab, K = topic.count, data = dfm2stm$meta, init.type = "Spectral") # this is the actual stm call
data.frame(t(labelTopics(model.stm, n = 10)$prob))
```


Let us plot a few heuristics. Note that these are [plot.STM](https://www.rdocumentation.org/packages/stm/versions/1.3.3/topics/plot.STM) custom plots included in the package. The plots show total topic share (a), topic constrast between two topics (b) and topic proportions within documents (c).

```{r}
plot(model.stm, type = "summary", text.cex = 0.5)
plot(model.stm, type = "perspectives", topics = c(6,4)) # Topics #2 and #4
plot(model.stm, type = "hist", topics = sample(1:topic.count, size = 9))
```

Next we do an effect estimation of the topic prevalence over time.

```{r}

model.stm.labels <- labelTopics(model.stm, 1:topic.count)
dfm2stm$meta$datum <- as.numeric(dfm2stm$meta$date)
model.stm.ee <- estimateEffect(1:topic.count ~ party + s(date), model.stm, meta = dfm2stm$meta)
```

Now we plot this estimation for a handful of topics (here 2 randomly chosen ones). 

```{r}
par(mfrow=c(3,3))
for (i in seq_along(sample(1:topic.count, size = 2)))
{
  plot(model.stm.ee, "year", method = "continuous", topics = i, main = paste0(model.stm.labels$prob[i,1:3], collapse = ", "), printlegend = F)
}
```

See below for plotting all 40 topics and saving the result to hard drive. 

```{r}
# Plots of topic prevalence over time
#png(width = 800, height = 800)
#for (i in 1:topic.count)
#{
#  plot(model.stm.ee, "year", method = "continuous", topics = i, main = paste0(model.stm.labels$prob[i,1:3], collapse = ", "), printlegend = F)
#}
#dev.off()
```




```{r}

#pablo


library(topicmodels)
library(MASS)
library(stm)

#Pablo's steps
fake_news_dtm_topicmodels <- convert(speech.corpus.dfm, to = "topicmodels")


K <- 30
lda <- LDA(speech.corpus.dfm.trim, k = K, method = "Gibbs", 
                control = list(verbose=25L, seed = 123, burnin = 50, iter = 100))

### empty rows, only zeros, how to get them and drop them.
rowTotals <- apply(speech.corpus.dfm.trim , 1, sum) #Find the sum of words in each Document
dtm.new   <- speech.corpus.dfm.trim[rowTotals> 0, ]           #remove all docs without words
```

```{r}
# Topic 
terms <- get_terms(lda, 15)
terms[,5]
topics <- get_topics(lda, 1)
head(topics)

paste(terms[,13], collapse=", ")
sample(newdata$text[topics==13], 1)
# add predicted topic to dataset
newdata$pred_topic <- topics
newdata$year <- substr(newdata$date, 1, 4) # extract year
head(newdata$year)
 # frequency table with articles about stock market, per year
tab <- table(newdata$year[newdata$pred_topic==13])
plot(tab)


#In other words, each document is considered to be about a mixture of #topics. 

#This information is included in the matrix `gamma` in the LDA object #(`theta` in the notation we used for the slides).

round(lda@gamma[1,], 2) #first row, ten digits
```
